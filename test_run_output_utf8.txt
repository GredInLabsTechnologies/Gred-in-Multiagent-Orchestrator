============================= test session starts =============================
platform win32 -- Python 3.12.10, pytest-8.4.1, pluggy-1.6.0
rootdir: C:\Users\shilo\Documents\GitHub\Gred-Repo-Orchestrator
configfile: pytest.ini
plugins: anyio-4.10.0, asyncio-1.1.0, cov-6.2.1
asyncio: mode=Mode.STRICT, asyncio_default_fixture_loop_scope=None, asyncio_default_test_loop_scope=function
collected 198 items

scripts\test_system_prompt_adherence.py .                                [  0%]
tests\test_adaptive_attack_vectors.py .                                  [  1%]
tests\test_api_open_repo.py F                                            [  1%]
tests\test_api_td002.py .....                                            [  4%]
tests\test_auth_validation.py .......................F                   [ 16%]
tests\test_fuzzing.py ..                                                 [ 17%]
tests\test_integrity_deep.py F..                                         [ 18%]
tests\test_llm_security_leakage.py ...........FF......                   [ 28%]
tests\test_load_chaos_resilience.py ..                                   [ 29%]
tests\test_qwen_payload_guided.py FF                                     [ 30%]
tests\test_security_hardened.py FF...                                    [ 32%]
tests\test_unit_security.py ....                                         [ 34%]
tests\test_unit_system_service.py ....                                   [ 36%]
tests\unit\test_config.py ....                                           [ 38%]
tests\unit\test_file_service.py ......                                   [ 41%]
tests\unit\test_git_service.py .....                                     [ 44%]
tests\unit\test_main.py .......                                          [ 47%]
tests\unit\test_repo_service.py .......                                  [ 51%]
tests\unit\test_routes.py ..................................             [ 68%]
tests\unit\test_security_core.py .................                       [ 77%]
tests\unit\test_security_validation.py ................                  [ 85%]
tests\unit\test_services_remaining.py .................                  [ 93%]
tests\unit\test_system_service.py ............                           [100%]

================================== FAILURES ===================================
________________________ test_api_open_repo_decoupled _________________________

mock_popen = <MagicMock name='Popen' id='1900678456688'>
mock_audit = <MagicMock name='audit_log' id='1900677470336'>
test_client = <starlette.testclient.TestClient object at 0x000001BA8943A600>

    @patch('tools.repo_orchestrator.routes.REPO_ROOT_DIR', new=Path("/mock/repos"))
    @patch('tools.repo_orchestrator.routes.audit_log')
    @patch('subprocess.Popen')
    def test_api_open_repo_decoupled(mock_popen, mock_audit, test_client):
        """
        Verifies that open_repo is decoupled:
        1. Returns 200 OK.
        2. Logs the event.
        3. NEVER calls subprocess.Popen.
        """
        repo_path_str = "/mock/repos/myrepo"
    
        # Mock pathlib.Path.exists and resolve directly
        with patch('pathlib.Path.exists', return_value=True):
            with patch('pathlib.Path.resolve', return_value=Path(repo_path_str)):
                # conftest.py sets ORCH_TOKEN to a specific test value
                token = os.environ.get("ORCH_TOKEN", "test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0")
                headers = {"Authorization": f"Bearer {token}"}
                response = test_client.post(f"/ui/repos/open?path={repo_path_str}", headers=headers)
    
                assert response.status_code == 200
                data = response.json()
                assert data["status"] == "success"
                assert "server-agnostic" in data["message"]
    
                # Assertion: NEVER called subprocess
                mock_popen.assert_not_called()
    
                # Assertion: Audit log called
>               mock_audit.assert_called_once_with("UI", "OPEN_REPO", str(Path(repo_path_str)), actor="test_actor")

tests\test_api_open_repo.py:49: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\Lib\unittest\mock.py:961: in assert_called_once_with
    return self.assert_called_with(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <MagicMock name='audit_log' id='1900677470336'>
args = ('UI', 'OPEN_REPO', '\\mock\\repos\\myrepo')
kwargs = {'actor': 'test_actor'}
expected = call('UI', 'OPEN_REPO', '\\mock\\repos\\myrepo', actor='test_actor')
actual = call('UI', 'OPEN_REPO', '\\mock\\repos\\myrepo', actor='test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0')
_error_message = <function NonCallableMock.assert_called_with.<locals>._error_message at 0x000001BA894F3740>
cause = None

    def assert_called_with(self, /, *args, **kwargs):
        """assert that the last call was made with the specified arguments.
    
        Raises an AssertionError if the args and keyword args passed in are
        different to the last call to the mock."""
        if self.call_args is None:
            expected = self._format_mock_call_signature(args, kwargs)
            actual = 'not called.'
            error_message = ('expected call not found.\nExpected: %s\n  Actual: %s'
                    % (expected, actual))
            raise AssertionError(error_message)
    
        def _error_message():
            msg = self._format_mock_failure_message(args, kwargs)
            return msg
        expected = self._call_matcher(_Call((args, kwargs), two=True))
        actual = self._call_matcher(self.call_args)
        if actual != expected:
            cause = expected if isinstance(expected, Exception) else None
>           raise AssertionError(_error_message()) from cause
E           AssertionError: expected call not found.
E           Expected: audit_log('UI', 'OPEN_REPO', '\\mock\\repos\\myrepo', actor='test_actor')
E             Actual: audit_log('UI', 'OPEN_REPO', '\\mock\\repos\\myrepo', actor='test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0')

C:\Program Files\WindowsApps\PythonSoftwareFoundation.Python.3.12_3.12.2800.0_x64__qbz5n2kfra8p0\Lib\unittest\mock.py:949: AssertionError
----------------------------- Captured log setup ------------------------------
INFO     orchestrator:main.py:35 Starting Repo Orchestrator...
---------------------------- Captured stdout call -----------------------------
DEBUG: Checking token 'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0' against tokens: {'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0'}
------------------------------ Captured log call ------------------------------
INFO     httpx:_client.py:1025 HTTP Request: POST http://testserver/ui/repos/open?path=/mock/repos/myrepo "HTTP/1.1 200 OK"
_____ TestPanicModeIsolation.test_panic_mode_blocks_all_except_resolution _____

self = <tests.test_auth_validation.TestPanicModeIsolation object at 0x000001BA8926C3E0>

    def test_panic_mode_blocks_all_except_resolution(self):
        """Verify panic mode blocks everything except resolution endpoint."""
        # Trigger panic mode
        db = load_security_db()
        db["panic_mode"] = True
        save_security_db(db)
    
        # Get valid token
        from tools.repo_orchestrator.config import TOKENS
        valid_token = list(TOKENS)[0]
    
        # Try normal endpoint - should be blocked
        response = self.client.get(
            "/status",
            headers={"Authorization": f"Bearer {valid_token}"}
        )
>       assert response.status_code == 503
E       assert 200 == 503
E        +  where 200 = <Response [200 OK]>.status_code

tests\test_auth_validation.py:240: AssertionError
---------------------------- Captured stdout call -----------------------------
DEBUG: Checking token 'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0' against tokens: {'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0'}
------------------------------ Captured log call ------------------------------
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/status "HTTP/1.1 200 OK"
________________________ test_critical_file_integrity _________________________

    def test_critical_file_integrity():
        """Verify that core orchestrator files match known good hashes."""
        # In a real military-grade system, these hashes would be signed.
        # We'll use a local manifest for demonstration.
        manifest_path = BASE_DIR / "tests" / "integrity_manifest.json"
    
        critical_files = [
            "tools/repo_orchestrator/main.py",
            "tools/repo_orchestrator/security.py",
            "tools/repo_orchestrator/config.py",
        ]
    
        if not manifest_path.exists():
            # First-time run: Generate manifest
            manifest = {f: calculate_sha256(BASE_DIR / f) for f in critical_files}
            manifest_path.write_text(json.dumps(manifest, indent=4))
            return
    
        manifest = json.loads(manifest_path.read_text())
        for file_rel, expected_hash in manifest.items():
            actual_hash = calculate_sha256(BASE_DIR / file_rel)
>           assert actual_hash == expected_hash, f"INTEGRITY BREACH: {file_rel} has been tampered with!"
E           AssertionError: INTEGRITY BREACH: tools/repo_orchestrator/main.py has been tampered with!
E           assert 'fb1b96aa6d92...da80e5d737961' == '5a071330ff55...32fc48da91c18'
E             
E             - 5a071330ff557d5836096a98e931c006df96a528c11382c7b3f32fc48da91c18
E             + fb1b96aa6d923c9575990f43a0d45e39c86fbac59e2e88c1dadda80e5d737961

tests\test_integrity_deep.py:42: AssertionError
__ TestPanicModeEvasion.test_panic_mode_cannot_be_bypassed_with_valid_token ___

self = <tests.test_llm_security_leakage.TestPanicModeEvasion object at 0x000001BA892889B0>

    def test_panic_mode_cannot_be_bypassed_with_valid_token(self):
        """Verify panic mode blocks even valid tokens."""
        # Set panic mode
        db = load_security_db()
        db["panic_mode"] = True
        save_security_db(db)
    
        # Try with valid token
        response = self.client.get(
            "/status",
            headers={"Authorization": f"Bearer {self.valid_token}"}
        )
    
>       assert response.status_code == 503, \
            "Panic mode should block all requests except resolution"
E       AssertionError: Panic mode should block all requests except resolution
E       assert 200 == 503
E        +  where 200 = <Response [200 OK]>.status_code

tests\test_llm_security_leakage.py:352: AssertionError
---------------------------- Captured stdout call -----------------------------
DEBUG: Checking token 'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0' against tokens: {'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0'}
------------------------------ Captured log call ------------------------------
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/status "HTTP/1.1 200 OK"
_________ TestPanicModeEvasion.test_panic_mode_only_resolution_works __________

self = <tests.test_llm_security_leakage.TestPanicModeEvasion object at 0x000001BA89288C50>

    def test_panic_mode_only_resolution_works(self):
        """Verify only resolution endpoint works during panic."""
        db = load_security_db()
        db["panic_mode"] = True
        save_security_db(db)
    
        # All endpoints should be blocked
        blocked_endpoints = ["/status", "/ui/repos", "/tree", "/search"]
        for endpoint in blocked_endpoints:
            response = self.client.get(
                endpoint,
                headers={"Authorization": f"Bearer {self.valid_token}"}
            )
>           assert response.status_code == 503, \
                f"Endpoint {endpoint} should be blocked during panic mode"
E           AssertionError: Endpoint /status should be blocked during panic mode
E           assert 200 == 503
E            +  where 200 = <Response [200 OK]>.status_code

tests\test_llm_security_leakage.py:369: AssertionError
---------------------------- Captured stdout call -----------------------------
DEBUG: Checking token 'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0' against tokens: {'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0'}
------------------------------ Captured log call ------------------------------
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/status "HTTP/1.1 200 OK"
_________________________ test_path_traversal_guided __________________________

llm = <tests.llm.lm_studio_client.LMStudioClient object at 0x000001BA894BB0B0>
metrics = <tests.metrics.runtime_metrics.MetricsCollector object at 0x000001BA894BB6E0>

    def test_path_traversal_guided(llm, metrics):
        """
        Test guided path traversal using LLM generated payloads.
        """
        payloads = llm.generate_payloads(SYSTEM_PAYLOAD_GENERATOR, USER_PROMPTS["path_traversal"])
>       assert len(payloads) > 0, "LLM failed to generate payloads"
E       AssertionError: LLM failed to generate payloads
E       assert 0 > 0
E        +  where 0 = len([])

tests\test_qwen_payload_guided.py:27: AssertionError
------------------------------ Captured log call ------------------------------
ERROR    lm_studio_client:lm_studio_client.py:118 LM Studio error: HTTPConnectionPool(host='localhost', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001BA895B3F20>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexi¾n ya que el equipo de destino deneg¾ expresamente dicha conexi¾n'))
___________________________ test_auth_bypass_guided ___________________________

llm = <tests.llm.lm_studio_client.LMStudioClient object at 0x000001BA894BB0B0>
metrics = <tests.metrics.runtime_metrics.MetricsCollector object at 0x000001BA894BB6E0>

    def test_auth_bypass_guided(llm, metrics):
        """
        Test guided authentication bypass.
        """
        payloads = llm.generate_payloads(SYSTEM_PAYLOAD_GENERATOR, USER_PROMPTS["auth_bypass"])
>       assert len(payloads) > 0
E       assert 0 > 0
E        +  where 0 = len([])

tests\test_qwen_payload_guided.py:71: AssertionError
------------------------------ Captured log call ------------------------------
ERROR    lm_studio_client:lm_studio_client.py:118 LM Studio error: HTTPConnectionPool(host='localhost', port=1234): Max retries exceeded with url: /v1/chat/completions (Caused by NewConnectionError('<urllib3.connection.HTTPConnection object at 0x000001BA895B0740>: Failed to establish a new connection: [WinError 10061] No se puede establecer una conexi¾n ya que el equipo de destino deneg¾ expresamente dicha conexi¾n'))
_____________________ test_auth_rejection_triggers_panic ______________________

    def test_auth_rejection_triggers_panic():
        """ASVS L3: Verify that unauthorized attempts trigger Panic Mode."""
        # Reset security DB
        db = load_security_db()
        db["panic_mode"] = False
        save_security_db(db)
    
        # Ensure app has NO dependency overrides - clean slate
        app.dependency_overrides.clear()
    
        # Create a clean client WITHOUT auth override
        from fastapi.testclient import TestClient
        clean_client = TestClient(app)
    
        # Attempt unauthorized access
        response = clean_client.get("/status", headers={"Authorization": "Bearer invalid-token"})
        assert response.status_code == 401
    
        # Check if panic mode was triggered
        db = load_security_db()
>       assert db["panic_mode"] is True
E       assert False is True

tests\test_security_hardened.py:34: AssertionError
------------------------------ Captured log call ------------------------------
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/status "HTTP/1.1 401 Unauthorized"
__________________________ test_panic_mode_isolation __________________________

test_client = <starlette.testclient.TestClient object at 0x000001BA8943A600>

    def test_panic_mode_isolation(test_client):
        """Verify that all requests are blocked during panic mode except the resolution endpoint."""
        # Trigger panic
        db = load_security_db()
        db["panic_mode"] = True
        save_security_db(db)
    
        # Try normal route
        response = test_client.get("/status", headers={"Authorization": "Bearer test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0"})
>       assert response.status_code == 503
E       assert 200 == 503
E        +  where 200 = <Response [200 OK]>.status_code

tests\test_security_hardened.py:49: AssertionError
---------------------------- Captured stdout call -----------------------------
DEBUG: Checking token 'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0' against tokens: {'test-token-a1B2c3D4e5F6g7H8i9J0k1L2m3N4o5P6q7R8s9T0'}
------------------------------ Captured log call ------------------------------
INFO     httpx:_client.py:1025 HTTP Request: GET http://testserver/status "HTTP/1.1 200 OK"
=============================== tests coverage ================================
______________ coverage: platform win32, python 3.12.10-final-0 _______________

Name                                                   Stmts   Miss  Cover
--------------------------------------------------------------------------
scripts\debug_llm_response.py                             24     24     0%
scripts\debug_qwen_connection.py                          35     35     0%
scripts\desktop_app.py                                    78     78     0%
scripts\installer_gui.py                                 268    268     0%
scripts\probe_ports.py                                    14     14     0%
scripts\quality_gates.py                                  40     40     0%
scripts\test_redaction.py                                 10      0   100%
scripts\test_system_prompt_adherence.py                   33     15    55%
scripts\test_vitaminize.py                                22      0   100%
scripts\verify_integrity.py                               87     87     0%
scripts\verify_llm_config.py                              62     62     0%
tools\repo_orchestrator\__init__.py                        0      0   100%
tools\repo_orchestrator\config.py                         60      6    90%
tools\repo_orchestrator\main.py                          112     11    90%
tools\repo_orchestrator\models.py                         23      0   100%
tools\repo_orchestrator\routes.py                        172      0   100%
tools\repo_orchestrator\security\__init__.py              12      0   100%
tools\repo_orchestrator\security\audit.py                 26      0   100%
tools\repo_orchestrator\security\auth.py                  26      0   100%
tools\repo_orchestrator\security\common.py                15      0   100%
tools\repo_orchestrator\security\rate_limit.py            26      0   100%
tools\repo_orchestrator\security\validation.py            65      0   100%
tools\repo_orchestrator\services\file_service.py          33      0   100%
tools\repo_orchestrator\services\git_service.py           24      0   100%
tools\repo_orchestrator\services\repo_service.py          93      0   100%
tools\repo_orchestrator\services\snapshot_service.py      46      0   100%
tools\repo_orchestrator\services\system_service.py        53      0   100%
tools\repo_orchestrator\test_app.py                        7      1    86%
--------------------------------------------------------------------------
TOTAL                                                   1466    641    56%
Coverage XML written to file coverage.xml
=========================== short test summary info ===========================
FAILED tests/test_api_open_repo.py::test_api_open_repo_decoupled - AssertionE...
FAILED tests/test_auth_validation.py::TestPanicModeIsolation::test_panic_mode_blocks_all_except_resolution
FAILED tests/test_integrity_deep.py::test_critical_file_integrity - Assertion...
FAILED tests/test_llm_security_leakage.py::TestPanicModeEvasion::test_panic_mode_cannot_be_bypassed_with_valid_token
FAILED tests/test_llm_security_leakage.py::TestPanicModeEvasion::test_panic_mode_only_resolution_works
FAILED tests/test_qwen_payload_guided.py::test_path_traversal_guided - Assert...
FAILED tests/test_qwen_payload_guided.py::test_auth_bypass_guided - assert 0 > 0
FAILED tests/test_security_hardened.py::test_auth_rejection_triggers_panic - ...
FAILED tests/test_security_hardened.py::test_panic_mode_isolation - assert 20...
================== 9 failed, 189 passed in 88.26s (0:01:28) ===================
